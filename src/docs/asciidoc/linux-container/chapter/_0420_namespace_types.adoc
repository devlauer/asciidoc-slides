ifndef::imagesdir[:imagesdir: ../images]
== Namespace Typen

[%step]
* Mount Namespace (2002 Kernel 2.4.19)
* UTS Namespace (2006 Kernel 2.6.19)
* IPC Namespace (2006 Kernel 2.6.19)
* PID Namespace (2008 Kernel 2.6.24)
* Network Namespace (2009 Kernel 2.6.29)
* User Namespace (2008-2013 Kernel 3.8)
* CGroups Namespace (2016 Kernel 4.6)
* Time Namespace (2020 Kernel 5.6 )

[.notes]
--
* Mount NS - unterschiedliche Mount Points, Dateisysteme
** Verzeichnisbaum sollte für jeden Container unterschiedlich sein
* UTS NS - für separate Hostnamen
** Unix Time Sharing - historisch ist der Hostname Teil der Datenstruktur utsname, die bei uname() system call verwendet wird (nodename and domainname Felder darin)
* IPC NS - Isolation for message queues etc.
** system v init
** postgresql
* PID NS - unterschiedliche Prozess-ID Bäume, wichtig für init-Systeme -> pid 1
* Network NS - Netzwerk Interfaces, Routing etc.
** ein Netzwerk Interface kann nur zu einem Namespace gehören
* User Namespace - Red Hatter Eric W. Biederman bereits in 2008 begonnen 1. Version
** root innerhalb, aber rootless außerhalb
* CGroups Namespace - nicht zu verwechseln mit CGroups, sondern mit der Sicht auf diese
* Time Namespace - unterschiedliche Systemzeiten
* syslog namespace (vorgeschlagen von Huawei, aber bisher abgelehnt)
* Prozesse können unterschiedliche Namespaces referenzieren
--

=== Mount namespace

* deluxe chroot()
* jeder neue Mount NS erbt alle Mounts des Parent NS
* jeder Mount NS kann sein eigenes RootFS haben
* gemountete Dateisysteme sind nur im gleichen NS sichtbar
* Achtung: Besonderheit spezielle Dateisysteme

[.notes]
--
* spezielle Dateisysteme des Systems erfordern einen Remount bspw. bei Containern
** procfs (to see your processes)
** devpts (to see your pseudo-terminals)
** /tmp (scoped per user, per service...)
* masking of /proc, /sys
* einen Mount von einem Namespace zum nächsten zu bewegen ist nicht einfach
* Container Image als RootFS mounten
--

=== UTS Namespace

* eigener Hostname
* eigener Domainname
* UTS, da nodename und domainname Teil der utsname Datenstrutur
* relevant bei uname() system call
* nützlich für die Frage: wo bin ich?

[.notes]
--
* Unix Time Sharing - historisch ist der Hostname Teil der Datenstruktur utsname, die bei uname() system call verwendet wird (nodename and domainname Felder darin)
--

=== IPC Namespace

* eigene IPC Semaphoren
* eigene IPC Message Queues
* eigenes IPC Shared Memory
* Vermeidung von Konflikten der Nutzer

[.notes]
--
* "System V IPC" msgget, semget, shmget
** das Problem xxget frägt nach einem Schlüssel, der abgeleitet ist von einem INode -> Lösung IPC Namespace
* abgelöst durch POSIX Alternativen: mq_open, sem_open, shm_open
* manche Tools wie PostgreSQL benötigen IPC
--

=== PID Namespace

* je NS eigener Prozessbaum mit eigener Nummerierung
* Besonderheit PID 1
* Prozesse sieht eigenen Prozessbaum oder den abgeleiteter NS
* PID NS können geschachtelt werden
* ein Prozess kann verschiedene PIDs je nach NS haben
* keine Sicht auf Parent- oder Geschwister-NS

[.notes]
--
* durch die eigene Nummerierung kann in jedem Namespace die PID 1 vergeben werden,
die wichtig für init-Systeme ist
* wird PID 1 gekillt ist der Namespace gekillt
* dadurch dass PID Namespaces geschachtelt sind, kann man Prozesse in Child-Namespaces
sehen und damit erreichen
--

=== Network Namespace

* eigener Network Stack je Namespace
** Network Interfaces (auch lo/127.0.0.1)
** IP Adressen, Routing Tables, iptables Rules, Sockets, /proc/net
* Netzwerk Interfaces lassen sich zwischen Namespaces verschieben
** ip link set dev eth0 netns PID

[.notes]
--
* Kommunikation zwischen Containern/Namespaces möglich
* eigene Netzwerkisolationen
* verschiedene Netzwerktopologien
** direkte Kommunikation wie mit Cross-Over-Kabel
* Anbindung an Host-Netzwerk über bridge
* geshartes Localhost möglich
* für Container sehr relevant (Docker pro Container ein Network-Namespace)
* Sharing möglich wie bei Pods oder Amazon ECS tasks (awsvpc networking mode)
--

=== User Namespace

* Isolierung von Benutzern und Gruppen
* Mapping von UID/GID (auch Ranges) per NS
** im neuen NS Root, im Host NS Non-Root
** /proc/PID/uid_map und /proc/PID/gid_map
* hierarchisch (Einfluss auf Capabilities)
* nicht mit anderen Host-NS kombinieren
* Sicherheitsverbesserung


[.note]
--
* UID 0 -> 1999 in Namespace 1 gemappt auf UID 10000 -> 11999 im Host
* map-File hat die Form inside-ns outside-ns range
* auch 1000 1000 1 möglich -> kein Superuser im Namespace
* alle verwendeten Dateisysteme sollten idmap mounts unterstützen
* in Docker erst seit einiger Zeit enthalten
* wichtig für rootless Container
* beim Erstellen eines neuen User Namespace wird SYS_CAP_ADMIN frisch vergeben,
damit Root im Namespace auch funktioniert
** die Rechte gelten nur für eigene Ressourcen (auch eigene andere Namespaces)
** Einschränkung für Kernel Module oder Mounts
** Unerwartete Themen, wenn mit Host Namespaces kombiniert (nicht Owner, daher dann Fehler)
* Problem Images mit festgelegten UIDs
** bei Verwendung in mehreren Containern mit unterschiedlichem Mapping
** deshalb automatisches chown durch Podman
** Problem Performance chown -> kernel mit metadata-only in OverlayFS
* eigene Datenstruktur kuid_t kgid_t im Kernel im Gegensatz zu uid_t und git_t für
alte Strukturen -> Fehler wenn gemischt
--

=== CGroups Namespace

* Isolierung/Virtualisierung spezifischer CGroups Pfade
* eigene Sicht auf /proc/$PID/cgroup Datei und cgroup mounts
* komplett isolierte Container ohne Sicht auf CGroup möglich

[.notes]
--
* Sicherheitsfeature, um Informationen bzgl. CGroups nicht nach außen zu geben.
* Normalerweise zeigt /proc/$PID/cgroup den kompletten CGroup-Baum, so dass auch andere
Informationen dort für den Container sichtbar werden
--

=== Time Namespace

* Virtualisiert/Isoliert
** CLOCK_MONOTONIC
** CLOCK_BOOTTIME
** Nicht CLOCK_REALTIME !!
* relevant bspw. für checkpoint/restore